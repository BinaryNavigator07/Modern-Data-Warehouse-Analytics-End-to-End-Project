# ğŸŒŸ **Modern Data Warehouse & Analytics End-to-End Project**  

ğŸ‘‹ Hello, Data Points! 
- Welcome to this data warehouse project!
- This project demonstrates modern data warehouse architecture and SQL analytics.

Welcome to this **Modern Data Warehouse & Analytics End-to-End Project** project using **PostgreSQL**! ğŸ¯  

## ğŸª„Modern Data Warehouse & Analytics End-to-End Project overview
![Data Warehouse Architecture](docs/my_notes/SQL_Projects.svg)

This repository provides a **step-by-step** approach to building a **scalable, efficient, and analytics-ready data warehouse**. It covers:  
âœ… **ETL Pipelines** (Extract, Transform, Load)  
âœ… **Data Modeling** (Star Schema)  
âœ… **Exploratory Data Analysis (EDA)**  
âœ… **SQL-based Reporting & Analytics**  
âœ… **Advanced-Data Analytsis & Reporting**  
ğŸ“ **Project Documentation**

---

## ğŸ—ï¸ **Data Architecture Overview**  

The project follows the **Medallion Architecture** with three layers:  

ğŸ“Œ **Bronze Layer (Raw Data)** â€“ Stores data directly from the source (CSV files).  
ğŸ“Œ **Silver Layer (Cleansed & Transformed Data)** â€“ Data is cleaned, structured, and normalized.  
ğŸ“Œ **Gold Layer (Business-Ready Data)** â€“ Optimized for analytics and reporting using a **star schema**.  

### **ğŸŒ Architecture Diagram:**  

![Data_Architecture](docs/warehouse/Data_Architecture.png)

---

## ğŸ“– **Project Overview**  

### ğŸ“Œ **Key Features & Highlights:**  

- **End-to-End Data Pipeline** â€“ From raw data to business insights
- **Automated ETL System** â€“ Scripts for running, scheduling, and monitoring ETL jobs
- **Centralized Configuration** â€“ Dynamic configuration system for file paths
- **Comprehensive Documentation** â€“ Architecture diagrams, data dictionaries, and more
- **Modular Design** â€“ Easily extendable for additional data sources
- **Best Practices** â€“ Following industry standards for data warehousing
- **Performance Optimization** â€“ Efficient SQL queries and indexing strategies

### ğŸ› ï¸ **Tech Stack:**  
- **Database:** PostgreSQL  
- **ETL Processing:** SQL, Python (optional)  
- **Data Visualization:** Power BI / Tableau (optional)  
- **Documentation & Diagramming:** Draw.io, Notion  

---

## ğŸ“‚ **Repository Structure**  

```
SQL-Data-Warehouse-Project/
â”œâ”€â”€ automation/           # ETL automation and orchestration scripts
â”‚   â”œâ”€â”€ run_etl.sh        # Main ETL execution script with error handling and logging
â”‚   â”œâ”€â”€ schedule_etl.sh   # Script for scheduling ETL jobs using cron
â”‚   â””â”€â”€ etl_monitor.sh    # Monitoring script for ETL job status and performance
â”‚
â”œâ”€â”€ datasets/             # Raw data from ERP and CRM systems
â”‚
â”œâ”€â”€ docs/                 # Project documentation, architecture diagrams, and outputs
â”‚   â”œâ”€â”€ bronze/           # Bronze layer documentation
â”‚   â”œâ”€â”€ silver/           # Silver layer documentation
â”‚   â”œâ”€â”€ gold/             # Gold layer documentation
â”‚   â””â”€â”€ warehouse/        # Overall warehouse architecture documentation
â”‚
â”œâ”€â”€ logs/                 # ETL execution logs
â”‚
â”œâ”€â”€ scripts/              # SQL scripts for ETL and transformations
â”‚   â”œâ”€â”€ bronze/           # Bronze layer scripts
â”‚   â”‚   â””â”€â”€ proc_load_bronze.sql  # Procedure to load data into bronze layer
â”‚   â”œâ”€â”€ silver/           # Silver layer scripts
â”‚   â”‚   â””â”€â”€ proc_load_silver.sql  # Procedure to transform data to silver layer
â”‚   â”œâ”€â”€ gold/             # Gold layer scripts
â”‚   â”‚   â””â”€â”€ ddl_gold.sql  # Scripts to create gold layer tables and views
â”‚   â”œâ”€â”€ config_paths.sql  # Configuration table for file paths
â”‚   â””â”€â”€ init_database.sql # Script to create the database and schemas
â”‚
â”œâ”€â”€ tests/                # Test scripts and quality control files
â”‚
â”œâ”€â”€ report/               # Analysis scripts and reports
â”‚   â”œâ”€â”€ 1_gold_layer_datasets/  # Datasets used for reporting
â”‚   â”œâ”€â”€ 2_eda_scripts/    # EDA scripts
â”‚   â””â”€â”€ output/           # Output from analysis
â”‚
â”œâ”€â”€ CONFIG_README.md      # Configuration system documentation
â”œâ”€â”€ README.md             # Project overview and instructions
â”œâ”€â”€ LICENSE               # License information
â””â”€â”€ requirements.txt      # Project dependencies
```  

---

## ğŸŒŠ Data Flow
![dataflow](docs/my_notes/data_flow.svg)
---

## ğŸš€ **Project Requirements**  

### ğŸ‘¨â€ğŸ’» **Data Engineering: Building the Data Warehouse**  
**Goal:** Develop a **PostgreSQL-based** data warehouse consolidating **sales data** for analytical reporting.  

âœ”ï¸ **Data Sources:** Import from **ERP & CRM (CSV files)**  
âœ”ï¸ **Data Quality:** Cleaning & handling missing values  
âœ”ï¸ **Integration:** Merging datasets into a **single analytical model**  
âœ”ï¸ **Data Modeling:** Implementing a **star schema** (Fact & Dimension tables)  
âœ”ï¸ **Documentation:** Clear **metadata & model descriptions**  


## ğŸ“Š **BI: Analytics & Reporting**  

ğŸ“Œ **Key Business Insights:**  
ğŸ”¸ **Customer Behavior Analysis** â€“ Understanding buying patterns  
ğŸ”¸ **Product Performance Metrics** â€“ Evaluating top-performing items  
ğŸ”¸ **Sales Trend Analysis** â€“ Identifying revenue patterns  

**Outcome:** ğŸ“ˆ Actionable reports for data-driven **business decisions**!  

---

## ğŸ“° Report - Data Analysis and Business Insights

This section summarizes the data analysis process and the resulting reports, providing valuable business insights.


![eda analysis](docs/my_notes/eda_steps_analysis.svg)


## ğŸ Data Exploration and Analysis

The analysis followed a structured approach, covering various aspects of the data:

1.  **Database Exploration:** Understanding the structure and relationships within the database.
2.  **Dimensions Exploration:** Analyzing the characteristics of the dimension tables (customers, products).
3.  **Date Range Exploration:** Identifying the time period covered by the data.
4.  **Measures Exploration:** Examining key metrics and their distributions.
5.  **Magnitude Exploration:** Understanding the scale of different measures.
6.  **Ranking Analysis:** Identifying top performers (e.g., customers, products).
7.  **Change Over Time Analysis:** Tracking trends and patterns over time.
8.  **Cumulative Analysis:** Examining the accumulated values of metrics.
9.  **Performance Analysis:** Evaluating the performance of different aspects of the business.
10. **Data Segmentation:** Grouping data into meaningful segments for targeted analysis.
11. **Part-to-Whole Analysis:** Understanding the contribution of different parts to the overall picture.


The EDA process was conducted using  SQL queries. The results of the EDA are stored in the `output` directory within the `report` folder.

---
## ğŸ› ï¸ **Setup & Installation Guide**  

### **ğŸ”¹ Prerequisites:**  
- Install **PostgreSQL** â†’ [Download PostgreSQL](https://www.postgresql.org/download/)  
- Clone this repository:  
  ```bash
  git clone https://github.com/BinaryNavigator07/Modern-Data-Warehouse-Analytics-End-to-End-Project
  ```
- Load sample datasets from the `/datasets/` folder.  

### **ğŸ”¹ Configuration Setup:**
1ï¸âƒ£ **Update Configuration:**
   - The project now uses a centralized configuration system with `config_paths.sql`
   - This file creates a configuration table (`config.file_paths`) that stores all file paths
   - Use the `config.get_path()` function to retrieve paths in your SQL procedures
   - See `CONFIG_README.md` for detailed instructions

### **ğŸ”¹ Running SQL Scripts:**  
1ï¸âƒ£ **Initialize Database:**  
   ```
   \i scripts/init_database.sql
   \i scripts/config_paths.sql
   ```
2ï¸âƒ£ **Run ETL Scripts Manually:**  
   ```
   -- For Bronze Layer
   CALL bronze.load_bronze();
   
   -- For Silver Layer
   CALL silver.load_silver();
   
   -- For Gold Layer
   \i scripts/gold/ddl_gold.sql
   ```
3ï¸âƒ£ **Run ETL with Automation:**  
   ```bash
   # Run the full ETL process
   ./automation/run_etl.sh
   
   # Schedule ETL jobs
   ./automation/schedule_etl.sh
   
   # Monitor ETL jobs
   ./automation/etl_monitor.sh
   ```
3ï¸âƒ£ **Start Analysis:** Query tables to generate insights!  

---

## ğŸ”— **Useful Links & Resources**  

ğŸ“Œ **Project Assets:**  
- ğŸ“‚ Dataset Folder: See the `datasets` directory
- ğŸ“ Project Documentation: See the `docs` directory
- ğŸ¨ [Diagramming Tool (Draw.io)](https://www.drawio.com/)  

---

## ğŸ“¢ **Connect & Collaborate!**  

ğŸ’¡ **Want to contribute?** Fork this repo and submit a **pull request**!  
ğŸ“© **Got questions?** Open an **issue** or reach out to me!  



ğŸ“§ Email: umaiesajid@gmail.com

